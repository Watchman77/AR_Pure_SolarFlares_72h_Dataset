{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO7jqzesq7mumkWEkBNU2E5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KP2KSPvaNTl-","executionInfo":{"status":"ok","timestamp":1764420581898,"user_tz":0,"elapsed":25462,"user":{"displayName":"Bamidele Akinwumi","userId":"03476110609219716134"}},"outputId":"d6a9649b-c838-47c9-a345-1446289db855"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","import os\n","\n","BASE = \"/content/drive/MyDrive/AR_Stratified\"\n","\n","# THE ONLY FILES WE WILL USE â€” RAW YEARLY FILES\n","year_files = {\n","    2010: \"hmi_2010_2010_fixed.csv\",\n","    2011: \"Sharp_Hmi_2011_2011_real1.csv\", # Changed .cs to .csv\n","    2012: \"hmi_2012_2012_fixed.csv\",\n","    2013: \"hmi_2013_2013_fixed.csv\",\n","    2014: \"hmi_2014_2014_fixed.csv\",\n","    2015: \"hmi_2015_2015_fixed.csv\",\n","    2016: \"hmi_2016_2016_fixed.csv\",\n","    2017: \"hmi_2017_2017_fixed.csv\",\n","    2018: \"hmi_2018_2018_fixed.csv\",\n","    2019: \"hmi_2019_2019_fixed.csv\",\n","    2020: \"hmi_2020_2020_fixed.csv\",\n","    2021: \"hmi_2021_2021_fixed.csv\",\n","    2022: \"hmi_2022_2022_fixed.csv\",\n","    2023: \"hmi_2023_2023_fixed.csv\",\n","    2024: \"hmi_2024_2024_fixed.csv\",\n","    2025: \"hmi_2025_2025_fixed.csv\",\n","}\n","\n","# -------------------------\n","# HELPERS\n","# -------------------------\n","\n","def parse_trec(df):\n","    df[\"T_REC\"] = df[\"T_REC\"].astype(str).str.strip()\n","    try:\n","        df[\"T_REC_dt\"] = pd.to_datetime(df[\"T_REC\"],\n","                                        format=\"%Y.%m.%d_%H:%M:%S_TAI\")\n","    except:\n","        df[\"T_REC_dt\"] = pd.to_datetime(\n","            df[\"T_REC\"].str.replace(\"_TAI\", \"\", regex=False),\n","            errors=\"coerce\"\n","        )\n","    df[\"year\"] = df[\"T_REC_dt\"].dt.year\n","    return df\n","\n","def extract_primary_ar(x):\n","    s = str(x)\n","    if s.lower() in [\"none\", \"nan\", \"missing\", \"\"]:\n","        return np.nan\n","    m = re.search(r\"\\d+\", s)\n","    return int(m.group()) if m else np.nan\n","\n","def ensure_noaa(df):\n","    # Normalize column names by stripping whitespace\n","    df.columns = df.columns.str.strip()\n","\n","    if \"NOAA_AR\" in df.columns:\n","        df[\"NOAA_AR\"] = pd.to_numeric(df[\"NOAA_AR\"],\n","                                      errors=\"coerce\").astype(\"Int64\")\n","    elif \"NOAA_ARS\" in df.columns:\n","        try:\n","            df[\"NOAA_AR\"] = df[\"NOAA_ARS\"].apply(extract_primary_ar).astype(\"Int64\")\n","        except KeyError:\n","            # This should theoretically not be hit if \"NOAA_ARS\" in df.columns was True.\n","            # However, given the observed error, it provides robustness.\n","            print(f\"Warning: Column 'NOAA_ARS' was checked to be present but caused a KeyError on access for year {df['year'].iloc[0] if 'year' in df.columns else 'unknown'}. Initializing NOAA_AR with NaN.\")\n","            df[\"NOAA_AR\"] = pd.Series([np.nan]*len(df), dtype=\"Int64\")\n","    else:\n","        # Neither NOAA_AR nor NOAA_ARS found\n","        df[\"NOAA_AR\"] = pd.Series([np.nan]*len(df), dtype=\"Int64\")\n","    return df\n","\n","# -------------------------\n","# CLEAN FROM SCRATCH\n","# -------------------------\n","\n","all_years = []\n","\n","print(\"=== CLEAN-SHEET BUILD STARTED ===\")\n","\n","for yr, fname in year_files.items():\n","    path = f\"{BASE}/{fname}\"\n","\n","    print(f\"\\nLoading {yr}: {fname}\")\n","    df = pd.read_csv(path)\n","\n","    # 1. Parse time + year\n","    df = parse_trec(df)\n","\n","    # 2. Extract NOAA_AR\n","    df = ensure_noaa(df)\n","\n","    # 3. Keep only this year's rows (in case file spills)\n","    df = df[df[\"year\"] == yr].copy()\n","\n","    # 4. Remove duplicates (T_REC_dt + AR)\n","    df = df.drop_duplicates(subset=[\"T_REC_dt\", \"NOAA_AR\"], keep=\"first\")\n","\n","    print(f\"  Final {yr} shape:\", df.shape)\n","\n","    all_years.append(df)\n","\n","# Combine all cleaned years\n","full = pd.concat(all_years, ignore_index=True)\n","\n","print(\"\\n=== AFTER MERGE ===\")\n","print(\"Shape:\", full.shape)\n","print(\"Years included:\", sorted(full[\"year\"].unique()))\n","print(\"\\nCounts per year:\")\n","print(full[\"year\"].value_counts().sort_index())\n","\n","# Save final clean file\n","OUT = f\"{BASE}/HMI_AR_2010_2025_CLEAN_FRESH.csv\"\n","full.to_csv(OUT, index=False)\n","\n","print(\"\\nSaved CLEAN-SHEET dataset to:\")\n","print(OUT)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KLIu31RsOEQ5","executionInfo":{"status":"ok","timestamp":1764430185101,"user_tz":0,"elapsed":7855,"user":{"displayName":"Bamidele Akinwumi","userId":"03476110609219716134"}},"outputId":"3cfb3ba1-2a97-46aa-842e-a5fff4dbeea6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["=== CLEAN-SHEET BUILD STARTED ===\n","\n","Loading 2010: hmi_2010_2010_fixed.csv\n","  Final 2010 shape: (803, 30)\n","\n","Loading 2011: Sharp_Hmi_2011_2011_real1.csv\n","  Final 2011 shape: (2195, 30)\n","\n","Loading 2012: hmi_2012_2012_fixed.csv\n","  Final 2012 shape: (2114, 30)\n","\n","Loading 2013: hmi_2013_2013_fixed.csv\n","  Final 2013 shape: (2618, 30)\n","\n","Loading 2014: hmi_2014_2014_fixed.csv\n","  Final 2014 shape: (2362, 30)\n","\n","Loading 2015: hmi_2015_2015_fixed.csv\n","  Final 2015 shape: (2196, 30)\n","\n","Loading 2016: hmi_2016_2016_fixed.csv\n","  Final 2016 shape: (1453, 30)\n","\n","Loading 2017: hmi_2017_2017_fixed.csv\n","  Final 2017 shape: (809, 30)\n","\n","Loading 2018: hmi_2018_2018_fixed.csv\n","  Final 2018 shape: (335, 30)\n","\n","Loading 2019: hmi_2019_2019_fixed.csv\n","  Final 2019 shape: (208, 30)\n","\n","Loading 2020: hmi_2020_2020_fixed.csv\n","  Final 2020 shape: (448, 30)\n","\n","Loading 2021: hmi_2021_2021_fixed.csv\n","  Final 2021 shape: (1183, 30)\n","\n","Loading 2022: hmi_2022_2022_fixed.csv\n","  Final 2022 shape: (2320, 30)\n","\n","Loading 2023: hmi_2023_2023_fixed.csv\n","  Final 2023 shape: (2932, 30)\n","\n","Loading 2024: hmi_2024_2024_fixed.csv\n","  Final 2024 shape: (2980, 31)\n","\n","Loading 2025: hmi_2025_2025_fixed.csv\n","  Final 2025 shape: (1648, 30)\n","\n","=== AFTER MERGE ===\n","Shape: (26604, 31)\n","Years included: [np.int32(2010), np.int32(2011), np.int32(2012), np.int32(2013), np.int32(2014), np.int32(2015), np.int32(2016), np.int32(2017), np.int32(2018), np.int32(2019), np.int32(2020), np.int32(2021), np.int32(2022), np.int32(2023), np.int32(2024), np.int32(2025)]\n","\n","Counts per year:\n","year\n","2010     803\n","2011    2195\n","2012    2114\n","2013    2618\n","2014    2362\n","2015    2196\n","2016    1453\n","2017     809\n","2018     335\n","2019     208\n","2020     448\n","2021    1183\n","2022    2320\n","2023    2932\n","2024    2980\n","2025    1648\n","Name: count, dtype: int64\n","\n","Saved CLEAN-SHEET dataset to:\n","/content/drive/MyDrive/AR_Stratified/HMI_AR_2010_2025_CLEAN_FRESH.csv\n"]}]},{"cell_type":"code","source":["print(\"Counts per year:\")\n","print(full[\"year\"].value_counts().sort_index())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W1YOOiBWQdPl","executionInfo":{"status":"ok","timestamp":1764430625468,"user_tz":0,"elapsed":39,"user":{"displayName":"Bamidele Akinwumi","userId":"03476110609219716134"}},"outputId":"7f4a41d0-c342-4c72-9f2c-d81687d03a64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Counts per year:\n","year\n","2010     803\n","2011    2195\n","2012    2114\n","2013    2618\n","2014    2362\n","2015    2196\n","2016    1453\n","2017     809\n","2018     335\n","2019     208\n","2020     448\n","2021    1183\n","2022    2320\n","2023    2932\n","2024    2980\n","2025    1648\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","\n","df2024 = pd.read_csv(\"/content/drive/MyDrive/AR_Stratified/hmi_2024_2024_fixed.csv\")\n","df2025 = pd.read_csv(\"/content/drive/MyDrive/AR_Stratified/hmi_2025_2025_fixed.csv\")\n","\n","print(\"2024 columns:\", len(df2024.columns))\n","print(df2024.columns.tolist())\n","\n","print(\"2025 columns:\", len(df2025.columns))\n","print(df2025.columns.tolist())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eo9YhqyXRnqH","executionInfo":{"status":"ok","timestamp":1764430879695,"user_tz":0,"elapsed":53,"user":{"displayName":"Bamidele Akinwumi","userId":"03476110609219716134"}},"outputId":"3a4746b0-9754-42db-b20a-2340f519f458"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2024 columns: 28\n","['T_REC', 'MEANGBZ', 'HARPNUM', 'R_VALUE', 'TOTUSJH', 'USFLUX', 'TOTPOT', 'MEANPOT', 'AREA_ACR', 'NOAA_ARS', 'LON_MIN', 'LON_MAX', 'LAT_MIN', 'LAT_MAX', 'QUALITY', 'USFLUX.1', 'MEANGAM', 'MEANGBT', 'MEANGBH', 'MEANJZD', 'TOTUSJZ', 'MEANALP', 'MEANJZH', 'ABSNJZH', 'SAVNCPP', 'MEANSHR', 'SHRGT45', 'AREA_ACR.1']\n","2025 columns: 27\n","['T_REC', 'MEANGBZ', 'HARPNUM', 'R_VALUE', 'TOTUSJH', 'USFLUX', 'TOTPOT', 'MEANPOT', 'AREA_ACR', 'NOAA_ARS', 'LON_MIN', 'LON_MAX', 'LAT_MIN', 'LAT_MAX', 'QUALITY', 'USFLUX.1', 'MEANGAM', 'MEANGBT', 'MEANGBH', 'MEANJZD', 'TOTUSJZ', 'MEANALP', 'MEANJZH', 'ABSNJZH', 'SAVNCPP', 'MEANSHR', 'SHRGT45']\n"]}]},{"cell_type":"code","source":["# Remove duplicate/useless columns\n","cols_to_drop = [\"USFLUX.1\", \"AREA_ACR.1\"]\n","\n","for col in cols_to_drop:\n","    if col in full.columns:\n","        full = full.drop(columns=[col])\n","\n","print(\"Final columns:\", len(full.columns))\n","print(full.columns)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lpb03at3TEC7","executionInfo":{"status":"ok","timestamp":1764431269751,"user_tz":0,"elapsed":49,"user":{"displayName":"Bamidele Akinwumi","userId":"03476110609219716134"}},"outputId":"6e4365bf-9eab-42c0-9838-e2093a0540dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Final columns: 29\n","Index(['T_REC', 'MEANGBZ', 'HARPNUM', 'R_VALUE', 'TOTUSJH', 'USFLUX', 'TOTPOT',\n","       'MEANPOT', 'AREA_ACR', 'NOAA_ARS', 'LON_MIN', 'LON_MAX', 'LAT_MIN',\n","       'LAT_MAX', 'QUALITY', 'MEANGAM', 'MEANGBT', 'MEANGBH', 'MEANJZD',\n","       'TOTUSJZ', 'MEANALP', 'MEANJZH', 'ABSNJZH', 'SAVNCPP', 'MEANSHR',\n","       'SHRGT45', 'T_REC_dt', 'year', 'NOAA_AR'],\n","      dtype='object')\n"]}]},{"cell_type":"code","source":["# =============================================================\n","# 1) BASE SETUP\n","# =============================================================\n","BASE = \"/content/drive/MyDrive/AR_Stratified\"\n","\n","# Load the CLEAN-SHEET merged dataset you built earlier\n","full = pd.read_csv(f\"{BASE}/HMI_AR_2010_2025_CLEAN_FRESH.csv\")\n","print(\"Loaded CLEAN FRESH dataset:\", full.shape)\n","print(\"Columns:\", list(full.columns))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r9u5jRVuVLlQ","executionInfo":{"status":"ok","timestamp":1764431828216,"user_tz":0,"elapsed":208,"user":{"displayName":"Bamidele Akinwumi","userId":"03476110609219716134"}},"outputId":"2d586d9e-77ff-4c94-8569-99a98d9616d5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded CLEAN FRESH dataset: (26604, 31)\n","Columns: ['T_REC', 'MEANGBZ', 'HARPNUM', 'R_VALUE', 'TOTUSJH', 'USFLUX', 'TOTPOT', 'MEANPOT', 'AREA_ACR', 'NOAA_ARS', 'LON_MIN', 'LON_MAX', 'LAT_MIN', 'LAT_MAX', 'QUALITY', 'USFLUX.1', 'MEANGAM', 'MEANGBT', 'MEANGBH', 'MEANJZD', 'TOTUSJZ', 'MEANALP', 'MEANJZH', 'ABSNJZH', 'SAVNCPP', 'MEANSHR', 'SHRGT45', 'T_REC_dt', 'year', 'NOAA_AR', 'AREA_ACR.1']\n"]}]},{"cell_type":"code","source":["# =============================================================\n","# 2) CORE 16 SHARP FEATURES + TIME + AR ID\n","# =============================================================\n","\n","core_features = [\n","    # Time + AR identity\n","    \"T_REC_dt\", \"year\", \"NOAA_AR\",\n","\n","    # 16 physics-driven AR features\n","    \"MEANGBZ\", \"MEANGAM\", \"MEANGBT\", \"MEANGBH\",\n","    \"MEANJZD\", \"TOTUSJZ\", \"MEANALP\", \"MEANJZH\",\n","    \"ABSNJZH\", \"SAVNCPP\", \"MEANSHR\", \"SHRGT45\",\n","    \"R_VALUE\", \"USFLUX\", \"TOTPOT\", \"TOTUSJH\"\n","]\n","\n","# Extract only the features available in the dataset\n","available_core = [c for c in core_features if c in full.columns]\n","missing_core = [c for c in core_features if c not in full.columns]\n","\n","print(\"Available CORE features:\", available_core)\n","print(\"Missing CORE features:\", missing_core)\n","\n","ml16 = full[available_core].copy()\n","\n","# Save file\n","path16 = f\"{BASE}/HMI_AR_2010_2025_ML_READY_16.csv\"\n","ml16.to_csv(path16, index=False)\n","\n","print(\"\\n=== ML-READY-16 DATASET ===\")\n","print(\"Shape:\", ml16.shape)\n","print(\"Saved to:\", path16)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HXKF9MDUVenL","executionInfo":{"status":"ok","timestamp":1764431888669,"user_tz":0,"elapsed":614,"user":{"displayName":"Bamidele Akinwumi","userId":"03476110609219716134"}},"outputId":"ee4ad8b3-5b5b-469e-aa8a-ade4bb292b49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Available CORE features: ['T_REC_dt', 'year', 'NOAA_AR', 'MEANGBZ', 'MEANGAM', 'MEANGBT', 'MEANGBH', 'MEANJZD', 'TOTUSJZ', 'MEANALP', 'MEANJZH', 'ABSNJZH', 'SAVNCPP', 'MEANSHR', 'SHRGT45', 'R_VALUE', 'USFLUX', 'TOTPOT', 'TOTUSJH']\n","Missing CORE features: []\n","\n","=== ML-READY-16 DATASET ===\n","Shape: (26604, 19)\n","Saved to: /content/drive/MyDrive/AR_Stratified/HMI_AR_2010_2025_ML_READY_16.csv\n"]}]},{"cell_type":"code","source":["# =============================================================\n","# 3) FULL 29-FEATURE ADVANCED DATASET\n","# =============================================================\n","\n","# Select safe columns (everything except duplicates)\n","drop_cols = [\"USFLUX.1\", \"AREA_ACR.1\"]  # Already removed earlier\n","\n","full29 = full[[c for c in full.columns if c not in drop_cols]].copy()\n","\n","path29 = f\"{BASE}/HMI_AR_2010_2025_ML_READY_29.csv\"\n","full29.to_csv(path29, index=False)\n","\n","print(\"\\n=== ML-READY-29 DATASET ===\")\n","print(\"Shape:\", full29.shape)\n","print(\"Saved to:\", path29)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TM92LnrbVv1-","executionInfo":{"status":"ok","timestamp":1764431959187,"user_tz":0,"elapsed":1177,"user":{"displayName":"Bamidele Akinwumi","userId":"03476110609219716134"}},"outputId":"487a3a11-ac43-4f73-e4c3-b6bf61c8ed0d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== ML-READY-29 DATASET ===\n","Shape: (26604, 29)\n","Saved to: /content/drive/MyDrive/AR_Stratified/HMI_AR_2010_2025_ML_READY_29.csv\n"]}]},{"cell_type":"code","source":["print(\"\\nYEAR COUNTS (16-feature dataset):\")\n","print(ml16[\"year\"].value_counts().sort_index())\n","\n","print(\"\\nYEAR COUNTS (29-feature dataset):\")\n","print(full29[\"year\"].value_counts().sort_index())\n","\n","print(\"\\nAny duplicates (T_REC_dt + NOAA_AR)?\")\n","print(full29.duplicated(subset=[\"T_REC_dt\", \"NOAA_AR\"]).sum())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kWhAOXIoWGoW","executionInfo":{"status":"ok","timestamp":1764432076234,"user_tz":0,"elapsed":62,"user":{"displayName":"Bamidele Akinwumi","userId":"03476110609219716134"}},"outputId":"f4acdbda-e842-46a3-dbe5-56df175cd270"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","YEAR COUNTS (16-feature dataset):\n","year\n","2010     803\n","2011    2195\n","2012    2114\n","2013    2618\n","2014    2362\n","2015    2196\n","2016    1453\n","2017     809\n","2018     335\n","2019     208\n","2020     448\n","2021    1183\n","2022    2320\n","2023    2932\n","2024    2980\n","2025    1648\n","Name: count, dtype: int64\n","\n","YEAR COUNTS (29-feature dataset):\n","year\n","2010     803\n","2011    2195\n","2012    2114\n","2013    2618\n","2014    2362\n","2015    2196\n","2016    1453\n","2017     809\n","2018     335\n","2019     208\n","2020     448\n","2021    1183\n","2022    2320\n","2023    2932\n","2024    2980\n","2025    1648\n","Name: count, dtype: int64\n","\n","Any duplicates (T_REC_dt + NOAA_AR)?\n","0\n"]}]},{"cell_type":"code","source":["print(\"\\nAny duplicates (T_REC_dt + NOAA_AR)?\")\n","print(full29.duplicated(subset=[\"T_REC_dt\", \"NOAA_AR\"]).sum())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7XNt0GHjZzAn","executionInfo":{"status":"ok","timestamp":1764433019732,"user_tz":0,"elapsed":246,"user":{"displayName":"Bamidele Akinwumi","userId":"03476110609219716134"}},"outputId":"8a3d5d75-7bc0-4db4-f6a7-f6190ffece49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Any duplicates (T_REC_dt + NOAA_AR)?\n","0\n"]}]},{"cell_type":"markdown","source":["# **PROCESSING OF THE GOES DATA**"],"metadata":{"id":"AYlxt3uMd4FC"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import glob\n","import re\n","\n","BASE = \"/content/drive/MyDrive/AR_Stratified\"\n","\n","goes_files = sorted(glob.glob(f\"{BASE}/GOES XRAY events for *.txt\"))\n","print(\"FILES FOUND:\", goes_files)\n","\n","rows = []\n","\n","def parse_goes_line(line):\n","    \"\"\"\n","    Robust parser for one GOES flare line.\n","    Returns dict or None if the line is not a flare record.\n","    \"\"\"\n","    line = line.strip()\n","\n","    # Skip empty / metadata / comments\n","    if not line:\n","        return None\n","    if \"Written\" in line or \"GOES\" in line or \"events\" in line.lower():\n","        return None\n","\n","    tokens = line.split()\n","    if len(tokens) < 4:\n","        return None\n","\n","    # First token must be a date like 3-Jan-2020\n","    if not re.match(r\"^\\d{1,2}-[A-Za-z]{3}-\\d{4}$\", tokens[0]):\n","        return None\n","\n","    date = tokens[0]\n","\n","    # Find index of flare class (A8.9, B1.0, C2.5, M3.1, X1.0)\n","    class_idx = None\n","    for i, t in enumerate(tokens):\n","        if re.match(r\"^[A-Z][0-9](\\.[0-9])?$\", t):\n","            class_idx = i\n","            break\n","    if class_idx is None:\n","        return None\n","\n","    # Times: assume tokens[1] = start, tokens[2] = peak if exists\n","    start_time = tokens[1] if len(tokens) > 1 else None\n","    peak_time = tokens[2] if len(tokens) > 2 else None\n","\n","    flare_class = tokens[class_idx]\n","\n","    # Location (if present) is next token after class\n","    location = tokens[class_idx + 1] if class_idx + 1 < len(tokens) else None\n","\n","    # Search for a 4â€“5 digit NOAA AR number in the tail\n","    NOAA_AR = np.nan\n","    for t in tokens[class_idx + 1:]:\n","        if re.fullmatch(r\"\\d{4,5}\", t):\n","            NOAA_AR = int(t)\n","            break\n","\n","    return {\n","        \"flare_date\": date,\n","        \"start_time\": start_time,\n","        \"peak_time\": peak_time,\n","        \"flare_class\": flare_class,\n","        \"location\": location,\n","        \"NOAA_AR\": NOAA_AR,\n","    }\n","\n","# =============================================================\n","# Parse all GOES files line by line\n","# =============================================================\n","\n","for file in goes_files:\n","    print(f\"\\nProcessing: {file}\")\n","    with open(file, \"r\", errors=\"ignore\") as f:\n","        for line in f:\n","            parsed = parse_goes_line(line)\n","            if parsed is not None:\n","                rows.append(parsed)\n","\n","goes_df = pd.DataFrame(rows)\n","\n","print(\"\\nAFTER PARSING ALL FILES:\")\n","print(\"Shape:\", goes_df.shape)\n","print(goes_df.head(15))\n","\n","# Build datetime column (only if we have data)\n","if not goes_df.empty:\n","    goes_df[\"flare_start_dt\"] = pd.to_datetime(\n","        goes_df[\"flare_date\"] + \" \" + goes_df[\"start_time\"],\n","        errors=\"coerce\"\n","    )\n","    goes_df[\"year\"] = goes_df[\"flare_start_dt\"].dt.year\n","\n","    print(\"\\nYears in GOES data:\", goes_df[\"year\"].value_counts().sort_index())\n","else:\n","    print(\"\\nâš ï¸ goes_df is empty â€“ parser matched nothing.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cr5e7RZwiPJb","executionInfo":{"status":"ok","timestamp":1764435233950,"user_tz":0,"elapsed":625,"user":{"displayName":"Bamidele Akinwumi","userId":"03476110609219716134"}},"outputId":"708fba57-1b8a-4374-a0c1-992936ecb7c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["FILES FOUND: ['/content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2010.txt', '/content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2011.txt', '/content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2012.txt', '/content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2013.txt', '/content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2014.txt', '/content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2015.txt', '/content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2016.txt', '/content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2017.txt', '/content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2018.txt', '/content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2019.txt', '/content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2020.txt', '/content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2021.txt', '/content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2022.txt', '/content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2023.txt', '/content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2024.txt', '/content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2025.txt']\n","\n","Processing: /content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2010.txt\n","\n","Processing: /content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2011.txt\n","\n","Processing: /content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2012.txt\n","\n","Processing: /content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2013.txt\n","\n","Processing: /content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2014.txt\n","\n","Processing: /content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2015.txt\n","\n","Processing: /content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2016.txt\n","\n","Processing: /content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2017.txt\n","\n","Processing: /content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2018.txt\n","\n","Processing: /content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2019.txt\n","\n","Processing: /content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2020.txt\n","\n","Processing: /content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2021.txt\n","\n","Processing: /content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2022.txt\n","\n","Processing: /content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2023.txt\n","\n","Processing: /content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2024.txt\n","\n","Processing: /content/drive/MyDrive/AR_Stratified/GOES XRAY events for 2025.txt\n","\n","AFTER PARSING ALL FILES:\n","Shape: (34723, 6)\n","    flare_date start_time peak_time flare_class location  NOAA_AR\n","0   1-Jan-2010      12:02     12:09        B1.9   S29W31  11039.0\n","1   1-Jan-2010      12:33     12:43        B2.3   S29W31  11039.0\n","2   1-Jan-2010      23:29     23:33        B1.1   S25W39  11039.0\n","3   2-Jan-2010      03:10     03:13        B1.1   S26W39  11039.0\n","4   2-Jan-2010      07:09     07:24        C1.0   S26W41      NaN\n","5   2-Jan-2010      07:58     08:05        B6.4   S25W38  11039.0\n","6   2-Jan-2010      09:01     09:10        B4.5   S30W44      NaN\n","7   2-Jan-2010      11:59     12:09        B4.8   S27W48      NaN\n","8   2-Jan-2010      14:08     14:16        C2.6   S28W40  11039.0\n","9   2-Jan-2010      22:39     22:46        B4.3   S27W48      NaN\n","10  2-Jan-2010      22:57     23:19        C3.1   S27W45      NaN\n","11  3-Jan-2010      01:17     01:22        C2.0   S28W49      NaN\n","12  3-Jan-2010      03:53     04:07        B6.1   S30W51      NaN\n","13  3-Jan-2010      07:43     07:46        B1.5   S31W58      NaN\n","14  3-Jan-2010      07:43     07:46        B1.5   S27W49  11039.0\n","\n","Years in GOES data: year\n","2010    1278\n","2011    2343\n","2012    1671\n","2013    1367\n","2014    2121\n","2015    1882\n","2016    1322\n","2017    1137\n","2018     477\n","2019     447\n","2020    1247\n","2021    2623\n","2022    4344\n","2023    5657\n","2024    5387\n","2025    1420\n","Name: count, dtype: int64\n"]}]},{"cell_type":"markdown","source":["# **STEP 1 â€“ Clean GOES & keep only M/X flares with known AR**"],"metadata":{"id":"oTbYiZJ_nyS7"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","BASE = \"/content/drive/MyDrive/AR_Stratified\"\n","\n","# If you still have goes_df from previous cell, reuse it.\n","# Otherwise reload from backup CSV (optional):\n","# goes_df = pd.read_csv(f\"{BASE}/GOES_ALL_PARSED.csv\", parse_dates=[\"flare_start_dt\"])\n","\n","print(\"GOES raw shape:\", goes_df.shape)\n","\n","# Drop rows without a valid flare_start_dt\n","goes_df = goes_df.dropna(subset=[\"flare_date\", \"start_time\"])\n","goes_df[\"flare_start_dt\"] = pd.to_datetime(\n","    goes_df[\"flare_date\"] + \" \" + goes_df[\"start_time\"],\n","    errors=\"coerce\"\n",")\n","goes_df = goes_df.dropna(subset=[\"flare_start_dt\"])\n","\n","# Standardise flare class\n","goes_df[\"flare_class\"] = goes_df[\"flare_class\"].astype(str).str.strip()\n","\n","# Split letter (A/B/C/M/X) and magnitude (e.g. 1.2, 5.6)\n","goes_df[\"class_letter\"] = goes_df[\"flare_class\"].str[0]\n","goes_df[\"class_mag\"] = pd.to_numeric(goes_df[\"flare_class\"].str[1:],\n","                                     errors=\"coerce\")\n","\n","# Keep only rows with a valid AR number & valid class\n","goes_df[\"NOAA_AR\"] = pd.to_numeric(goes_df[\"NOAA_AR\"], errors=\"coerce\").astype(\"Int64\")\n","goes_df = goes_df.dropna(subset=[\"NOAA_AR\", \"class_letter\"])\n","\n","# Filter to M & X flares (for now â€“ strongest events)\n","goes_mx = goes_df[goes_df[\"class_letter\"].isin([\"M\", \"X\"])].copy()\n","\n","goes_mx[\"year\"] = goes_mx[\"flare_start_dt\"].dt.year\n","\n","print(\"\\nM+X FLARES ONLY:\")\n","print(\"Shape:\", goes_mx.shape)\n","print(goes_mx.head(10))\n","\n","print(\"\\nM+X counts by year:\")\n","print(goes_mx[\"year\"].value_counts().sort_index())\n"],"metadata":{"id":"sNbw0f92lWnu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764436717566,"user_tz":0,"elapsed":212,"user":{"displayName":"Bamidele Akinwumi","userId":"03476110609219716134"}},"outputId":"cec3c01c-2fa8-4927-9231-51f05b58c89b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GOES raw shape: (34723, 8)\n","\n","M+X FLARES ONLY:\n","Shape: (2240, 10)\n","      flare_date start_time peak_time flare_class location  NOAA_AR  \\\n","102  20-Jan-2010      10:46     10:59        M1.8   S25E87    11041   \n","166   7-Feb-2010      02:20     02:34        M6.4   N21E11    11045   \n","192   8-Feb-2010      11:57     12:03        M1.1   N21W07    11045   \n","234  12-Feb-2010      11:19     11:26        M8.3   N33E13    11046   \n","238  12-Feb-2010      17:52     18:08        M1.1   N33E10    11046   \n","517  12-Jun-2010      00:30     00:57        M2.0   N23W47    11081   \n","530  13-Jun-2010      05:30     05:39        M1.0   S24W82    11079   \n","531  13-Jun-2010      05:30     05:39        M1.0   S24W82    11079   \n","710   7-Aug-2010      17:48     18:24        M1.0   N14E37    11093   \n","711   7-Aug-2010      17:55     18:24        M1.0   N14E37    11093   \n","\n","         flare_start_dt  year class_letter  class_mag  \n","102 2010-01-20 10:46:00  2010            M        1.8  \n","166 2010-02-07 02:20:00  2010            M        6.4  \n","192 2010-02-08 11:57:00  2010            M        1.1  \n","234 2010-02-12 11:19:00  2010            M        8.3  \n","238 2010-02-12 17:52:00  2010            M        1.1  \n","517 2010-06-12 00:30:00  2010            M        2.0  \n","530 2010-06-13 05:30:00  2010            M        1.0  \n","531 2010-06-13 05:30:00  2010            M        1.0  \n","710 2010-08-07 17:48:00  2010            M        1.0  \n","711 2010-08-07 17:55:00  2010            M        1.0  \n","\n","M+X counts by year:\n","year\n","2010     11\n","2011     94\n","2012    102\n","2013     40\n","2014    205\n","2015    105\n","2016     14\n","2017     40\n","2019      1\n","2021     21\n","2022    199\n","2023    391\n","2024    883\n","2025    134\n","Name: count, dtype: int64\n"]}]},{"cell_type":"markdown","source":["# S**TEP 2 â€“ Load AR dataset & attach 3-day preflare labels**"],"metadata":{"id":"j4lM607ToQ8E"}},{"cell_type":"markdown","source":["Weâ€™ll use your 16-feature core AR dataset and add a binary label:\n","label_MX_3d = 1 â†’ this AR snapshot is within 3 days before an M/X flare from that AR\n","label_MX_3d = 0 â†’ otherwise"],"metadata":{"id":"WD86C9r7oflO"}},{"cell_type":"code","source":["# ==========================================\n","# Load AR 16-feature dataset\n","# ==========================================\n","ar = pd.read_csv(f\"{BASE}/HMI_AR_2010_2025_ML_READY_16.csv\")\n","\n","print(\"AR shape:\", ar.shape)\n","print(\"AR columns:\", list(ar.columns))\n","\n","# Ensure datetime\n","ar[\"T_REC_dt\"] = pd.to_datetime(ar[\"T_REC_dt\"], errors=\"coerce\")\n","ar[\"year\"] = pd.to_numeric(ar[\"year\"], errors=\"coerce\").astype(\"Int64\")\n","ar[\"NOAA_AR\"] = pd.to_numeric(ar[\"NOAA_AR\"], errors=\"coerce\").astype(\"Int64\")\n","\n","# Drop AR rows with missing time or AR id\n","ar = ar.dropna(subset=[\"T_REC_dt\", \"NOAA_AR\"]).copy()\n","print(\"\\nAR after dropping missing T_REC_dt/NOAA_AR:\", ar.shape)\n","\n","# Initialise label\n","ar[\"label_MX_3d\"] = 0\n","\n","# (Optional) store if it was followed by X vs M flare\n","ar[\"future_max_class\"] = pd.Series(index=ar.index, dtype=\"object\")\n","\n","# Sort AR and GOES by time for sanity\n","ar = ar.sort_values([\"NOAA_AR\", \"T_REC_dt\"]).reset_index(drop=True)\n","goes_mx = goes_mx.sort_values([\"NOAA_AR\", \"flare_start_dt\"]).reset_index(drop=True)\n","\n","# ==========================================\n","# Attach 3-day preflare labels\n","# ==========================================\n","from tqdm import tqdm  # if not installed, comment out or install\n","\n","print(\"\\nLabelling AR rows with 3-day preflare window for M/X flares...\")\n","\n","for idx, row in tqdm(goes_mx.iterrows(), total=len(goes_mx)):\n","    ar_num = row[\"NOAA_AR\"]\n","    flare_time = row[\"flare_start_dt\"]\n","    flare_cls = row[\"flare_class\"]\n","\n","    # 3-day window before flare (inclusive)\n","    start_win = flare_time - pd.Timedelta(days=3)\n","    end_win   = flare_time\n","\n","    mask = (\n","        (ar[\"NOAA_AR\"] == ar_num) &\n","        (ar[\"T_REC_dt\"] >= start_win) &\n","        (ar[\"T_REC_dt\"] <= end_win)\n","    )\n","\n","    if mask.any():\n","        ar.loc[mask, \"label_MX_3d\"] = 1\n","\n","        # Optionally track most severe flare class seen\n","        # (e.g. if both M and X, we keep X)\n","        current = ar.loc[mask, \"future_max_class\"]\n","        new_vals = flare_cls\n","\n","        # If existing is NaN or lower class, overwrite\n","        # (Simple logic: X > M; within same letter keep higher magnitude)\n","        def choose_best(old, new):\n","            if pd.isna(old):\n","                return new\n","            # Compare by class letter priority\n","            if old[0] == new[0]:\n","                try:\n","                    return old if float(old[1:]) >= float(new[1:]) else new\n","                except:\n","                    return old\n","            # X > M > C etc.\n","            order = {\"X\": 3, \"M\": 2, \"C\": 1, \"B\": 0, \"A\": 0}\n","            return old if order.get(old[0], 0) >= order.get(new[0], 0) else new\n","\n","        ar.loc[mask, \"future_max_class\"] = [\n","            choose_best(o, new_vals) for o in current\n","        ]\n","\n","print(\"\\nLabel distribution (label_MX_3d):\")\n","print(ar[\"label_MX_3d\"].value_counts())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-zg_UER7oJ_M","executionInfo":{"status":"ok","timestamp":1764436939159,"user_tz":0,"elapsed":5739,"user":{"displayName":"Bamidele Akinwumi","userId":"03476110609219716134"}},"outputId":"fd4341ce-d52f-4bae-926e-73a96a1ba5e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["AR shape: (26604, 19)\n","AR columns: ['T_REC_dt', 'year', 'NOAA_AR', 'MEANGBZ', 'MEANGAM', 'MEANGBT', 'MEANGBH', 'MEANJZD', 'TOTUSJZ', 'MEANALP', 'MEANJZH', 'ABSNJZH', 'SAVNCPP', 'MEANSHR', 'SHRGT45', 'R_VALUE', 'USFLUX', 'TOTPOT', 'TOTUSJH']\n","\n","AR after dropping missing T_REC_dt/NOAA_AR: (22355, 19)\n","\n","Labelling AR rows with 3-day preflare window for M/X flares...\n"]},{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2240/2240 [00:05<00:00, 402.18it/s]"]},{"output_type":"stream","name":"stdout","text":["\n","Label distribution (label_MX_3d):\n","label_MX_3d\n","0    20888\n","1     1467\n","Name: count, dtype: int64\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["out_path = f\"{BASE}/HMI_AR_2010_2025_ML_READY_16_LABELED_MX3D.csv\"\n","ar.to_csv(out_path, index=False)\n","print(\"\\nSaved labeled AR dataset to:\")\n","print(out_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"21ZFs_mFuX_9","executionInfo":{"status":"ok","timestamp":1764438519417,"user_tz":0,"elapsed":1052,"user":{"displayName":"Bamidele Akinwumi","userId":"03476110609219716134"}},"outputId":"b4c31a1e-623e-40e4-cf89-066381b21c4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Saved labeled AR dataset to:\n","/content/drive/MyDrive/AR_Stratified/HMI_AR_2010_2025_ML_READY_16_LABELED_MX3D.csv\n"]}]},{"cell_type":"markdown","source":["# **ðŸ”¥ 1. Prepare full GOES (all classes Aâ€“X, with AR + time)**"],"metadata":{"id":"hcvSp9jRsZUJ"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","\n","# Start from full GOES (not just M/X)\n","goes_all = goes_df.copy()\n","\n","# Ensure datetime & clean fields\n","goes_all = goes_all.dropna(subset=[\"flare_date\", \"start_time\"])\n","goes_all[\"flare_start_dt\"] = pd.to_datetime(\n","    goes_all[\"flare_date\"] + \" \" + goes_all[\"start_time\"],\n","    errors=\"coerce\"\n",")\n","goes_all = goes_all.dropna(subset=[\"flare_start_dt\"])\n","\n","goes_all[\"flare_class\"] = goes_all[\"flare_class\"].astype(str).str.strip()\n","goes_all[\"class_letter\"] = goes_all[\"flare_class\"].str[0]\n","goes_all[\"class_mag\"] = pd.to_numeric(goes_all[\"flare_class\"].str[1:], errors=\"coerce\")\n","\n","goes_all[\"NOAA_AR\"] = pd.to_numeric(goes_all[\"NOAA_AR\"], errors=\"coerce\").astype(\"Int64\")\n","goes_all = goes_all.dropna(subset=[\"NOAA_AR\", \"class_letter\"])\n","\n","goes_all[\"year\"] = goes_all[\"flare_start_dt\"].dt.year\n","\n","print(\"GOES (all classes) shape:\", goes_all.shape)\n","print(goes_all.head(10))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"05lrzshisYyI","executionInfo":{"status":"ok","timestamp":1764438576631,"user_tz":0,"elapsed":260,"user":{"displayName":"Bamidele Akinwumi","userId":"03476110609219716134"}},"outputId":"4854b18a-541f-4cc6-b8f0-6efe57f727de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GOES (all classes) shape: (27667, 10)\n","    flare_date start_time peak_time flare_class location  NOAA_AR  \\\n","0   1-Jan-2010      12:02     12:09        B1.9   S29W31    11039   \n","1   1-Jan-2010      12:33     12:43        B2.3   S29W31    11039   \n","2   1-Jan-2010      23:29     23:33        B1.1   S25W39    11039   \n","3   2-Jan-2010      03:10     03:13        B1.1   S26W39    11039   \n","5   2-Jan-2010      07:58     08:05        B6.4   S25W38    11039   \n","8   2-Jan-2010      14:08     14:16        C2.6   S28W40    11039   \n","14  3-Jan-2010      07:43     07:46        B1.5   S27W49    11039   \n","16  3-Jan-2010      10:50     11:03        B1.5   S28W56    11039   \n","21  3-Jan-2010      15:52     16:03        B6.7   S28W57    11039   \n","29  5-Jan-2010      08:46     08:52        B1.2   S28W81    11039   \n","\n","        flare_start_dt  year class_letter  class_mag  \n","0  2010-01-01 12:02:00  2010            B        1.9  \n","1  2010-01-01 12:33:00  2010            B        2.3  \n","2  2010-01-01 23:29:00  2010            B        1.1  \n","3  2010-01-02 03:10:00  2010            B        1.1  \n","5  2010-01-02 07:58:00  2010            B        6.4  \n","8  2010-01-02 14:08:00  2010            C        2.6  \n","14 2010-01-03 07:43:00  2010            B        1.5  \n","16 2010-01-03 10:50:00  2010            B        1.5  \n","21 2010-01-03 15:52:00  2010            B        6.7  \n","29 2010-01-05 08:46:00  2010            B        1.2  \n"]}]},{"cell_type":"markdown","source":["# **2. Copy AR data and add multi-class labels (A/B/C/M/X + times)**"],"metadata":{"id":"ScY-Vq0vtEIY"}},{"cell_type":"markdown","source":["Weâ€™ll:\n","\n","Keep your existing ar (with label_MX_3d)\n","\n","Make a new copy called ar_all\n","\n","Add:\n","\n","label_any_3d â†’ 0/1 (any flare Aâ€“X within 3 days)\n","\n","future_max_any_class â†’ strongest flare class (A/B/C/M/X + magnitude) in next 3 days\n","\n","future_flare_start_dt_any â†’ datetime of that flare\n","\n","future_flare_peak_time_any â†’ peak time string"],"metadata":{"id":"0B4vSN6GtPH3"}},{"cell_type":"markdown","source":["Strength order:\n","\n","X > M > C > B > A; within same letter, higher magnitude wins (e.g. M6.4 > M1.1)."],"metadata":{"id":"94WZlUKetYmP"}},{"cell_type":"code","source":["# Work on a fresh copy so we don't disturb the previous labelled dataset\n","ar_all = ar.copy()\n","\n","# Initialise new labels\n","ar_all[\"label_any_3d\"] = 0\n","ar_all[\"future_max_any_class\"] = pd.Series(index=ar_all.index, dtype=\"object\")\n","ar_all[\"future_flare_start_dt_any\"] = pd.NaT\n","ar_all[\"future_flare_peak_time_any\"] = pd.Series(index=ar_all.index, dtype=\"object\")\n","\n","# Ensure types\n","ar_all[\"T_REC_dt\"] = pd.to_datetime(ar_all[\"T_REC_dt\"], errors=\"coerce\")\n","ar_all[\"NOAA_AR\"] = pd.to_numeric(ar_all[\"NOAA_AR\"], errors=\"coerce\").astype(\"Int64\")\n","ar_all = ar_all.dropna(subset=[\"T_REC_dt\", \"NOAA_AR\"]).copy()\n","\n","goes_all = goes_all.sort_values([\"NOAA_AR\", \"flare_start_dt\"]).reset_index(drop=True)\n","ar_all = ar_all.sort_values([\"NOAA_AR\", \"T_REC_dt\"]).reset_index(drop=True)\n","\n","# Helper: convert class string like 'M6.4' to numeric score\n","def flare_score(cls_str):\n","    if pd.isna(cls_str):\n","        return -1\n","    s = str(cls_str).strip()\n","    if len(s) < 2:\n","        return -1\n","    letter = s[0]\n","    try:\n","        mag = float(s[1:])\n","    except Exception:\n","        mag = 0.0\n","    order = {\"X\": 5, \"M\": 4, \"C\": 3, \"B\": 2, \"A\": 1}\n","    return order.get(letter, 0) * 100 + mag\n","\n","print(\"\\nLabelling AR rows with 3-day preflare window for ANY flare class (Aâ€“X)...\")\n","\n","for _, f in goes_all.iterrows():\n","    ar_num = f[\"NOAA_AR\"]\n","    flare_time = f[\"flare_start_dt\"]\n","    flare_cls = f[\"flare_class\"]\n","    peak_time = f.get(\"peak_time\", None)\n","\n","    # 3-day preflare window\n","    start_win = flare_time - pd.Timedelta(days=3)\n","    end_win   = flare_time\n","\n","    mask = (\n","        (ar_all[\"NOAA_AR\"] == ar_num) &\n","        (ar_all[\"T_REC_dt\"] >= start_win) &\n","        (ar_all[\"T_REC_dt\"] <= end_win)\n","    )\n","\n","    if not mask.any():\n","        continue\n","\n","    new_score = flare_score(flare_cls)\n","    idxs = ar_all.index[mask]\n","\n","    for idx in idxs:\n","        old_cls = ar_all.at[idx, \"future_max_any_class\"]\n","        old_score = flare_score(old_cls)\n","\n","        # If new flare stronger than any already assigned, overwrite\n","        if new_score > old_score:\n","            ar_all.at[idx, \"label_any_3d\"] = 1\n","            ar_all.at[idx, \"future_max_any_class\"] = flare_cls\n","            ar_all.at[idx, \"future_flare_start_dt_any\"] = flare_time\n","            ar_all.at[idx, \"future_flare_peak_time_any\"] = peak_time\n","\n","print(\"\\nLabel distribution (label_any_3d):\")\n","print(ar_all[\"label_any_3d\"].value_counts())\n","\n","print(\"\\nTop future_max_any_class values:\")\n","print(ar_all[\"future_max_any_class\"].value_counts().head(20))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dwVUwp4ateIS","executionInfo":{"status":"ok","timestamp":1764438638283,"user_tz":0,"elapsed":41377,"user":{"displayName":"Bamidele Akinwumi","userId":"03476110609219716134"}},"outputId":"184ec1fd-aae5-447f-af3d-45f0b94d4e5a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Labelling AR rows with 3-day preflare window for ANY flare class (Aâ€“X)...\n","\n","Label distribution (label_any_3d):\n","label_any_3d\n","0    13144\n","1     9211\n","Name: count, dtype: int64\n","\n","Top future_max_any_class values:\n","future_max_any_class\n","C1.1    191\n","C1.2    184\n","C1.0    179\n","C1.5    177\n","C1.7    176\n","C1.4    173\n","C1.6    168\n","C1.3    153\n","C2.2    149\n","C1.9    148\n","C1.8    144\n","C2.3    136\n","C3.0    129\n","M1.1    124\n","C2.1    117\n","M1.0    116\n","C2.0    116\n","C2.9    108\n","C2.6    106\n","C2.4     98\n","Name: count, dtype: int64\n"]}]},{"cell_type":"code","source":["out_path_all = f\"{BASE}/HMI_AR_2010_2025_ML_READY_16_LABELED_ALLCLASS_3D.csv\"\n","ar_all.to_csv(out_path_all, index=False)\n","print(\"\\nSaved multi-class (Aâ€“X) labelled dataset to:\")\n","print(out_path_all)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t2zEPawdvbps","executionInfo":{"status":"ok","timestamp":1764438694729,"user_tz":0,"elapsed":771,"user":{"displayName":"Bamidele Akinwumi","userId":"03476110609219716134"}},"outputId":"68f2ca75-6307-4107-aa7f-0d9de330bc2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Saved multi-class (Aâ€“X) labelled dataset to:\n","/content/drive/MyDrive/AR_Stratified/HMI_AR_2010_2025_ML_READY_16_LABELED_ALLCLASS_3D.csv\n"]}]}]}